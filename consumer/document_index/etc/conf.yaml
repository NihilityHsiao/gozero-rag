Name: knowledge-document-index-consumer
# config.yaml
Mysql:
  DataSource: "root:root@tcp(127.0.0.1:13306)/gozero_rag?charset=utf8mb4&parseTime=True&loc=Local"

Cache:
  - Host: 127.0.0.1:6379
    Pass: "root"
    Type: node

Oss:
  Type: minio
  Endpoint: localhost:9000
  AccessKey: "minioadmin"
  SecretKey: "minioadmin"
  UseSSL: false
  BucketName: "rag-storage"

# milvus, qdrant, es
# VectorStore:
#   Type: "milvus" 
#   Endpoint: "localhost:19530"
#   Username: ""
#   Password: ""
#   Database: ""

ElasticSearch:
  Addresses:
    - "http://localhost:9200"
  Username: ""
  Password: ""
# 相关文档: https://go-zero.dev/docs/tutorials/message-queue/kafka
KqConsumerConf:
  Name: KnowledgeDocumentIndexConsumer
  Brokers:
    - localhost:9092
  Group: KnowledgeDocumentIndexGroup
  Topic: prod.rag.knowledge.document.index
  # 如果新的 topic kafka 没有对应的 offset 信息,或者当前的 offset 无效了(历史数据被删除),那么需要指定从头(first)消费还是从尾(last)部消费
  Offset: first
  #  go-queue 内部是起多个 goroutine 从 kafka 中获取信息写入进程内的 channel，这个参数是控制此处的 goroutine 数量
  #（并不是真正消费时的并发 goroutine 数量）
  Consumers: 8
  # 当 Consumers 中的多个 goroutine 将 kafka 消息拉取到进程内部的 channel 后，
  # 我们要真正消费消息写入我们自己逻辑，
  # go-queue 内部通过此参数控制当前消费的并发 goroutine 数量
  Processors: 8
  ForceCommit: false
