

- [ ] langchain 为什么用 state graph？eino有类似的吗？和普通函数调用链有什么区别？
- [ ] 百万级并发的agent调度系统怎么设计？
- [ ] agent底层架构、ReACT、Plan-and-Execute
- [ ] 冷启动问题：新文档的embedding怎么快速索引？不重建索引的情况下怎么更新向量？



# 检索优化
- [ ] 检索优化：向量检索+BM25, 融合; cross-encoder 重新排序
- [ ] Contextual Compression：把无关的内容压缩掉

# 生成优化
- [ ] Self-RAG：让模型自己判断要不要检索
- [ ] CRAG：检测检索结果的质量，如果不行就回退到网络搜索


# Memory
- 工作记忆：当前上下文
- 短期记忆：定期总结
- 长期记忆：向量数据库

# 可观测性
Agent系统一个任务可能涉及几十次LLM调用，每次调用的输入输出不一样，怎么追踪？
- agent完整推理链路

# 成本优化
- 智能模型路由：简单任务用便宜的模型，复杂任务用贵的模型
- Prompt压缩：用LLMLingua这种工具，把Prompt从500 tokens压缩到200 tokens
- 语义缓存：相似的问题直接返回缓存的答案